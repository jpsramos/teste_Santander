{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81182cd9-1f60-40a6-b9d2-dd9597670a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs carregados com sucesso.\n",
      "Tabela Delta 'access_log' criada com sucesso.\n",
      "Exercício 1: Top 10 IPs com mais acessos.\n",
      "+--------------+------+\n",
      "|ip            |count |\n",
      "+--------------+------+\n",
      "|10.216.113.172|109523|\n",
      "|10.173.141.213|45836 |\n",
      "|10.220.112.1  |43910 |\n",
      "|10.41.69.177  |33991 |\n",
      "|10.169.128.121|22516 |\n",
      "|10.203.77.198 |18754 |\n",
      "|10.96.173.111 |17122 |\n",
      "|10.53.149.243 |16706 |\n",
      "|10.31.77.18   |16692 |\n",
      "|10.118.250.30 |15779 |\n",
      "+--------------+------+\n",
      "\n",
      "Exercício 2: Top 6 endpoints mais acessados.\n",
      "+--------------------------------------+-----+\n",
      "|endpoint                              |count|\n",
      "+--------------------------------------+-----+\n",
      "|/                                     |98793|\n",
      "|/release-schedule/                    |25920|\n",
      "|/search/                              |22985|\n",
      "|/release-schedule                     |18926|\n",
      "|/release-schedule/?p=1&r=&l=&o=&rpp=10|8410 |\n",
      "|/news/                                |7488 |\n",
      "+--------------------------------------+-----+\n",
      "\n",
      "Exercício 3: Quantidade de Client IPs distintos: 330322\n",
      "Exercício 4: Quantidade de dias distintos representados no arquivo: 791\n",
      "Exercício 5: Análise de volumes de dados retornados.\n",
      "Volume total de dados retornado: 805219137550 bytes\n",
      "Maior volume de dados em uma única resposta: 80215074 bytes\n",
      "Menor volume de dados em uma única resposta: 1 bytes\n",
      "Volume médio de dados retornado: 195016.05 bytes\n",
      "Exercício 6: Dia da semana com o maior número de erros do tipo 'HTTP Client Error'.\n",
      "+-----------+-----+\n",
      "|day_of_week|count|\n",
      "+-----------+-----+\n",
      "|Friday     |15070|\n",
      "|Wednesday  |12630|\n",
      "|Monday     |12159|\n",
      "|Thursday   |11760|\n",
      "|Tuesday    |11480|\n",
      "|Saturday   |11039|\n",
      "|Sunday     |10523|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "\n",
    "class SantanderAccessLog:\n",
    "    def __init__(self, log_file_path, table_name):\n",
    "        self.log_file_path = log_file_path\n",
    "        self.table_name = table_name\n",
    "        self.spark = SparkSession.builder.appName(\"Santander Access Log\").getOrCreate()\n",
    "        self.logs_df = None\n",
    "\n",
    "    def load_logs(self):\n",
    "        try:\n",
    "            log_pattern = r'(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \"(.*?)\" (\\d{3}) (\\d+)'\n",
    "            \n",
    "            def parse_log_line(line):\n",
    "                match = re.match(log_pattern, line)\n",
    "                if match:\n",
    "                    return (\n",
    "                        match.group(1),  # ip\n",
    "                        match.group(2),  # client_identd\n",
    "                        match.group(3),  # user_id\n",
    "                        match.group(4),  # datetime\n",
    "                        match.group(5),  # request\n",
    "                        int(match.group(6)),  # status\n",
    "                        int(match.group(7)),  # size\n",
    "                    )\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "            logs_rdd = self.spark.sparkContext.textFile(self.log_file_path)\n",
    "            parsed_logs_rdd = logs_rdd.map(parse_log_line).filter(lambda x: x is not None)\n",
    "\n",
    "            schema = StructType([\n",
    "                StructField(\"ip\", StringType(), True),\n",
    "                StructField(\"client_identd\", StringType(), True),\n",
    "                StructField(\"user_id\", StringType(), True),\n",
    "                StructField(\"datetime\", StringType(), True),\n",
    "                StructField(\"request\", StringType(), True),\n",
    "                StructField(\"status\", IntegerType(), True),\n",
    "                StructField(\"size\", IntegerType(), True),\n",
    "            ])\n",
    "\n",
    "            self.logs_df = self.spark.createDataFrame(parsed_logs_rdd, schema=schema)\n",
    "            self.logs_df = self.logs_df.withColumn(\"datetime\", F.to_timestamp(F.col(\"datetime\"), \"dd/MMM/yyyy:HH:mm:ss Z\"))\n",
    "            print(\"Logs carregados com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar os logs: {e}\")\n",
    "\n",
    "    def write_to_delta_table(self):\n",
    "        try:\n",
    "            self.logs_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(self.table_name)\n",
    "            print(f\"Tabela Delta '{self.table_name}' criada com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar a tabela Delta '{self.table_name}': {e}\")\n",
    "\n",
    "    def exercise_1(self):\n",
    "        try:\n",
    "            top_ips = self.logs_df.groupBy(\"ip\").count().orderBy(F.desc(\"count\")).limit(10)\n",
    "            print(\"Exercício 1: Top 10 IPs com mais acessos.\")\n",
    "            top_ips.show(truncate=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 1: {e}\")\n",
    "\n",
    "    def exercise_2(self):\n",
    "        try:\n",
    "            df = self.logs_df.withColumn(\"endpoint\", F.split(F.col(\"request\"), \" \").getItem(1))\n",
    "            filtered_df = df.filter(~F.lower(F.col(\"endpoint\")).rlike(\n",
    "                r'\\.(php|css|js|png|jpg|jpeg|gif|ico|svg|woff|ttf|eot|otf|map|json|xml|txt|zip|gz|tar|rar|7z)$'\n",
    "            ))\n",
    "            top_endpoints = filtered_df.groupBy(\"endpoint\").count().orderBy(F.desc(\"count\")).limit(6)\n",
    "            print(\"Exercício 2: Top 6 endpoints mais acessados.\")\n",
    "            top_endpoints.show(truncate=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 2: {e}\")\n",
    "\n",
    "    def exercise_3(self):\n",
    "        try:\n",
    "            distinct_ips = self.logs_df.select(\"ip\").distinct().count()\n",
    "            print(f\"Exercício 3: Quantidade de Client IPs distintos: {distinct_ips}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 3: {e}\")\n",
    "\n",
    "    def exercise_4(self):\n",
    "        try:\n",
    "            distinct_days = self.logs_df.withColumn(\"date\", F.to_date(F.col(\"datetime\"))).select(\"date\").distinct().count()\n",
    "            print(f\"Exercício 4: Quantidade de dias distintos representados no arquivo: {distinct_days}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 4: {e}\")\n",
    "\n",
    "    def exercise_5(self):\n",
    "        try:\n",
    "            results = self.logs_df.agg(\n",
    "                F.sum(\"size\").alias(\"total_volume\"),\n",
    "                F.max(\"size\").alias(\"max_volume\"),\n",
    "                F.min(\"size\").alias(\"min_volume\"),\n",
    "                F.avg(\"size\").alias(\"avg_volume\")\n",
    "            ).collect()[0]\n",
    "            print(\"Exercício 5: Análise de volumes de dados retornados.\")\n",
    "            print(f\"Volume total de dados retornado: {results['total_volume']} bytes\")\n",
    "            print(f\"Maior volume de dados em uma única resposta: {results['max_volume']} bytes\")\n",
    "            print(f\"Menor volume de dados em uma única resposta: {results['min_volume']} bytes\")\n",
    "            print(f\"Volume médio de dados retornado: {results['avg_volume']:.2f} bytes\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 5: {e}\")\n",
    "\n",
    "    def exercise_6(self):\n",
    "        try:\n",
    "            df = self.logs_df.withColumn(\"day_of_week\", F.date_format(F.col(\"datetime\"), \"EEEE\"))\n",
    "            client_errors_df = df.filter((F.col(\"status\") >= 400) & (F.col(\"status\") < 500))\n",
    "            errors_by_day = client_errors_df.groupBy(\"day_of_week\").count().orderBy(F.desc(\"count\"))\n",
    "            print(\"Exercício 6: Dia da semana com o maior número de erros do tipo 'HTTP Client Error'.\")\n",
    "            errors_by_day.show(truncate=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no exercício 6: {e}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "log_file_path = \"/FileStore/tables/access_log-5.txt\"\n",
    "table_name = \"access_log\"\n",
    "\n",
    "santander_log = SantanderAccessLog(log_file_path, table_name)\n",
    "santander_log.load_logs()\n",
    "santander_log.write_to_delta_table()\n",
    "santander_log.exercise_1()\n",
    "santander_log.exercise_2()\n",
    "santander_log.exercise_3()\n",
    "santander_log.exercise_4()\n",
    "santander_log.exercise_5()\n",
    "santander_log.exercise_6()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4453449408998945,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Teste_Santander",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
